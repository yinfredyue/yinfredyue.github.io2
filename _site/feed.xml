<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://yyin-dev.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://yyin-dev.github.io/" rel="alternate" type="text/html" /><updated>2025-01-20T23:02:29-05:00</updated><id>https://yyin-dev.github.io/feed.xml</id><title type="html">Yue Yin’s website</title><subtitle>Stuffs about programming and learning</subtitle><author><name>Yue Yin</name></author><entry><title type="html">Ai Paper Notes</title><link href="https://yyin-dev.github.io/AI-paper-notes/" rel="alternate" type="text/html" title="Ai Paper Notes" /><published>2025-01-20T00:00:00-05:00</published><updated>2025-01-20T00:00:00-05:00</updated><id>https://yyin-dev.github.io/AI-paper-notes</id><content type="html" xml:base="https://yyin-dev.github.io/AI-paper-notes/"><![CDATA[<p>The following are notes while reading papers in the <a href="https://www.latent.space/p/2025-papers">2025 AI Engineer Reading List</a> They are personal notes and are not refined for an external audience really. Just in case it’s helpful for someone else.</p>

<h2 id="frontier-models"><strong>Frontier Models</strong></h2>

<ul>
  <li><strong>Improving Language Understanding by Generative Pre-Training</strong> (GPT-1) (2018) by OpenAI
    <ul>
      <li>Introduces GPT-1 (117M params).</li>
      <li>Key idea: Pre-train + fine-tuning. Use <strong>unsupervised</strong> learning to first pre-train a generative model on a large corpus of text, and then fine-tune this model on specific downstream tasks with <strong>supervised</strong> learning. This paper presents a foundational framework for transfer learning in NLP, where pre-trained models can be fine-tuned on specific tasks to achieve significant improvements in performance.</li>
    </ul>
  </li>
  <li><strong>Language Models are Unsupervised Multitask Learners</strong> (GPT-2) (2019) by OpenAI
    <ul>
      <li>Introduces GPT-2 (1.5B params)</li>
      <li>Key idea: GPT-2 performs well on a variety of language tasks without needing task-specific training data. One of the innovative aspects of GPT-2 is its ability to adapt to diverse tasks simply by conditioning on task-specific <strong>prompts</strong>.
        <ul>
          <li>When prompted with a question, it can generate a coherent answer based solely on its pre-training knowledge. For example, when evaluated on reading comprehension question-answering task, GPT-2 produces answer when conditioned on the reading material and a final token <code class="language-plaintext highlighter-rouge">A:</code> (Section 3.5), with greedy decoding. When evaluated on text summarization task, GPT-2 produces answer when conditioned on the article and the text <code class="language-plaintext highlighter-rouge">TL;DR:</code> .</li>
          <li>When given a few examples within the prompt, the model can adapt its outputs to align closely with the demonstrated behavior in those examples. For example, when evaluated on machine translation task, GPT-2 produces translation when conditioned on examples pairs of the format <code class="language-plaintext highlighter-rouge">english sentence = french sentence</code> and then after a final prompt of <code class="language-plaintext highlighter-rouge">english sentence =</code>, with greedy decoding.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Language Models are Few-Shot Learners</strong> (GPT-3) (2020) by OpenAI
    <ul>
      <li>Introduces GPT-3 (175B params)</li>
      <li>Key idea: the GPT-3 paper demonstrated that <strong>scaling up</strong> LLMs greatly improves few-shot performance, <strong>without extensive fine-tuning</strong>. GPT-3 is trained without fine-tuning and performs tasks purely based on prompting.
        <ul>
          <li>Model performance improves with prompting, and with the number of examples in the model’s context. Few-shot learning also improves dramatically with model size.</li>
          <li>In-context learning: providing inference-time demonstrations to the model. The terms “zero-shot”, “one-shot”, and “few-shot” refer to the number of demonstrations provided at inference time.</li>
          <li>The models scale up well and didn’t hit the ceiling yet.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Evaluating Large Language Models Trained on Code</strong> (Codex) (2021) by OpenAI
    <ul>
      <li>Key idea: Codex models are GPT models fine-tuned on code to complete coding tasks. The paper focuses on generating standalone Python functions from docstrings. The correctness of the generated code is evaluated automatically against unit tests.
        <ul>
          <li>Models
            <ul>
              <li>Codex is a GPT model fine-tuned on publicly available code from GitHub.</li>
              <li>Codex-S, standing for “supervised fine-tuned”, is further trained on a dataset of standalone, correctly-implemented Python functions.</li>
              <li>Codex-D is trained on pairs of function signatures, reference solutions, and corresponding docstrings. The model focuses on generating docstrings from given implementation.</li>
            </ul>
          </li>
          <li>Codex uses repeated sampling from the model. By generating multiple code samples for a given prompt, the chance of obtaining at least one solution increased significantly.</li>
          <li>Pass@k evaluation metrics: the probability of a model generating at least one correct solution within k samples.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Training language models to follow instructions with human feedback</strong> (InstructGPT) (2022) by OpenAI
    <ul>
      <li>Key: After supervised fine-tuning, use RLHF to align the model.
        <ul>
          <li>Misalignment: the objective function of LLM - predicting the next word - is different from the objective of “following user instructions carefully and safely and helpfully”. Thus, the LLM objective is <em>misaligned</em>.</li>
          <li>RLHF:
            <ul>
              <li>Step 1: Collect demonstration data of desired behavior, and perform supervised fine-tuning.</li>
              <li>Step 2: Collect comparison data of model outputs and human ranking, to train a reward model.</li>
              <li>Step 3: Fine-tune the model with RL, using PPO algorithm.</li>
            </ul>
          </li>
          <li>Alignment tax occurs when an alignment procedure negatively impacts performance on certain tasks. The author discussed mitigating this by adding pretraining updates to the PPO fine-tuning process.</li>
        </ul>
      </li>
      <li>Aside: The initial ChatGPT model is a sibling model of InstructGPT.</li>
    </ul>

    <p><img src="../assets/images/sft_rlhf.png" alt="image.png" /></p>
  </li>
  <li><strong>GPT-4 Technical Report</strong> (GPT-4) (2023) by OpenAI
    <ul>
      <li>Key Idea: GPT-4 is a <strong>multimodal</strong> model capable of processing both image and text input to generate text outputs. The paper describes methods for <strong>reliably predicating</strong> model capabilities and mitigating safety risks through reinforcement learning from human feedback (<strong>RLHF</strong>).
        <ul>
          <li>Predictable scaling: Training LLM is expensive. OpenAI created infrastructure and optimization methods with consistent behavior across various scale. Model capabilities is predicated by fitting a power law.</li>
          <li>RLHF: Simply increasing the size of language models doesn’t guarantee improved alignment with user intent. LLMs can still produce false, toxic, or unhelpful outputs. RLHF is used to fine-tune the model. This involves collecting demonstration data of desired behavior and comparison data where human labelers rank different outputs.
            <ul>
              <li>RLHF significantly enhances the models’s safety by reducing the likelihood of generating harmful content and improving the model’s ability to follow user instructions. However, RLHF doesn’t appear to significantly improve model’s capabilities. Evaluation shows that the base GPT-4 and post-RLHF model achieve similar scores on some benchmarks.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="https://openai.com/index/hello-gpt-4o/">GPT-4o</a> (2024) by OpenAI
    <ul>
      <li>Prior to GPT-4o, ChatGPT supported voice through a pipeline of three separate models: audio to text → GPT-4 → text to audio. This had high latency, and GPT-4 lost a lot of information because it couldn’t directly observe tone, multiple speakers or background noise, and it couldn’t output laughter, singing or express emotion.</li>
      <li>GPT-4o is a trained end-to-end across text, vision, and audio, meaning that all inputs and outputs are processed by the same model.</li>
    </ul>
  </li>
  <li><a href="https://openai.com/index/introducing-openai-o1-preview/">GPT-o1</a>, <a href="https://openai.com/index/learning-to-reason-with-llms/">technical report</a>, <a href="https://openai.com/index/openai-o1-system-card/">system card</a> (2024) By OpenAI
    <ul>
      <li>GPT-o1 spends more time thinking before responding. It’s ”a significant advancement for complex reasoning tasks and represents a new level of AI capability”. O1 ranks 89th percentile on Codeforces, among top 500 students in USA Math Olympiad, and exceeds human PhD-level on a benchmark of physics, biology, and chemistry problems.</li>
      <li>O1 uses chain of thought to think longer before responding. The chain of thought is hidden from the user though.</li>
      <li>Compared with GPT-4o, o1 is slightly worse at text writing, but better at programming, data analysis, and math.</li>
    </ul>
  </li>
  <li><strong>Deliberative Alignment: Reasoning Enables Safer Language Models</strong> (GPT-o3) (2024) by OpenAI
    <ul>
      <li>TL;DR: Instead of aligning the model using human-labelled outputs and RLHF that implicitly encodes safety specifications, ask the model to reason through safety specifications explicitly with CoT and then perform RL. The complex reasoning ability, enabled by CoT, is foundational here.</li>
      <li>Previously, LLMs are aligned using Supervised Fine Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF). There are two limitations with this approach. First, LLMs respond instantly without deliberation even in complex safety scenarios. Second, LLMs infer safety standards indirectly from labelled examples, instead of directly learning the safety specifications.</li>
      <li>Deliberative Alignment addresses the two issues by teaching LLM to explicitly reason through safety specifications before producing an answer, using the chain-of-thought (CoT) reasoning ability introduced in GPT-o1.</li>
      <li>The method involves two core stages, integrating process-based and outcome-based supervision. The training procedure requires <strong>no human-labeled completions</strong>.
        <ul>
          <li>In the first stage, teach the model to reason through safety specifications with CoT using supervised fine-tuning on <code class="language-plaintext highlighter-rouge">(prompt, CoT, output)</code>. The dataset is constructed by prompting another o-type model with the safety specifications, generating model completions, and stripping away the safe specifications from the prompt.</li>
          <li>In the second stage, use RL to train the model. The reward model is a judge LLM that is given the safety specifications.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>The Claude 3 Model Family: Opus, Sonnet, Haiku</strong> (Claude 3) (2024) by Anthropic
    <ul>
      <li>Not particularly interesting</li>
    </ul>
  </li>
  <li>“Gemini: A Family of Highly Capable Multimodal Models” (Gemini 1) (2023) by DeepMind
    <ul>
      <li>Not particularly interesting</li>
    </ul>
  </li>
  <li><strong>LLaMA: Open and Efficient Foundation Language Models</strong> (LLaMA 1) (2023) by Meta
    <ul>
      <li>The objective is to train a series of language models that deliver optimal performance across different <strong>inference</strong> budgets. Smaller models trained on more data can be more efficient at inference, making them cheaper to run in real-world applications, despite potentially longer training times.</li>
      <li>LLaMA models are trained on more tokens than typically used and achieve performance similar to other larger models like GPT-3, Chinchilla and PaLM. LLaMa 1 is trained exclusively on public data.</li>
    </ul>
  </li>
  <li><strong>LLaMA 2: Open Foundation and Fine-Tuned Chat Models</strong> (LLaMA 2) (2023) by Meta
    <ul>
      <li>Fine-tunes for chat: LLaMA 2-Chat</li>
      <li>Llama 2 uses a technique called “Ghost Attention” (GAtt), which involves augmenting user messages with instructions throughout the dialogue history during fine-tuning. This allows the model to consistently adhere to instructions over multiple turns. E.g. “Ack like Washington”.</li>
    </ul>
  </li>
  <li><strong>The Llama 3 Herd of Models</strong> (LLaMA 3) (2024) by Meta
    <ul>
      <li>LLaMa 3 405B. The paper identified three key levers to develop LLM:
        <ul>
          <li>Data: Improved both quantity and quality. LLaMA 3 was trained on 15T tokens, compared to 1.5T  for Llama 2.</li>
          <li>Scale: Trained at a larger scale with 50x FLOPs than Llama2.</li>
          <li>Managing complexity: To improve scaling, use supervised finetuning (SFT), rejection sampling (RS) and direct preference optimization (DPO), instead of RLHF with PPO.</li>
        </ul>
      </li>
      <li>Shared details about the development process. Dataset construction, large-scale training, model architecture, multimodality support, etc.</li>
      <li>Maybe worth a more in-depth read?</li>
    </ul>
  </li>
  <li><strong>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</strong> (DeepSeek-v1) (2024)
    <ul>
      <li>Explores scaling law of hyperparameters. Proposes new scaling law variant. Argues that scaling behavior is affected by the quality of dataset.</li>
    </ul>
  </li>
  <li><strong>DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</strong> (DeepSeek-v2) (2024)
    <ul>
      <li>DeepSeek-v2 provides economical training and efficient inference. It replaces traditional multi-head attention with multi-head latent attention to reduce KV cache, and uses MoE to reduce training cost. With only 21B activated params, it achieves similar performance with Llama 70B.</li>
      <li>MLA: See <a href="https://www.notion.so/MHA-vs-MQA-vs-GQA-vs-MLA-1818cacb1fea804cb3cbe40ee55ff31a?pvs=21">MHA vs. MQA vs. GQA vs. MLA</a></li>
    </ul>
  </li>
  <li><strong>DeepSeek-v3 Technical Report</strong> (DeepSeek-v3) (2024)
    <ul>
      <li>On top of DeekSeek-v2’s, adds an auxiliary-loss-free load balancing to DeekSeekMoE, and Multi-Token Prediction (MTP). Cost-effective due to using FP8 mixed precision training and meticulous engineering optimizations in the training framework. Achieved economical efficiency and strong performance.
        <ul>
          <li>MoE model performance suffer from unbalanced expert load. Auxiliary loss is a common solution but it could impair model performance. DeepSeek-v3 introduces a bias term and dynamically adjust it during training time to encourage load balancing.</li>
          <li>MTP: Introduced by Meta. Predict multiple tokens instead of a single one at each position.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="prompting-icl-chain-of-thought">Prompting, ICL, Chain-of-Thought</h2>

<ul>
  <li><strong>The Prompt Report: A Systematic Survey of Prompting Techniques</strong> (2024)
    <ul>
      <li>Key idea: A comprehensive survey of prompting techniques. The authors review 1565 relevant papers, identifying 58 text-based prompting techniques and 40 techniques for other modalities.
        <ul>
          <li>I didn’t read the full paper but created a <a href="https://notebooklm.google.com/notebook/4cc30576-75a4-4f6a-a97e-190a9ceab9d1">NotebookLM</a> generated from a <a href="https://www.latent.space/p/learn-prompting">podcast</a> on it.</li>
          <li>Zero-shot, few-shot, Chain of Thought, Tree of Thought, Decomposition, Ensembling, Self criticism.</li>
          <li>Automatic Prompting Engineering using tools like DSPy.</li>
          <li>Structured output prompting.</li>
          <li>Multimodal prompting extends prompt engineering beyond text to incorporate other modalities like images, audio, and video.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</strong> (2022)
    <ul>
      <li>Key idea: Chain-of-thought prompting improves the reasoning ability of the model by prompts consisting of triples: &lt;input, chain of though, output&gt;. A chain of thought is a series of intermediate natural language reasoning steps that lead to the final output.
        <ul>
          <li>An emergent ability is a capability that arises unexpectedly as a model’s scale increases. Chain-of-thought prompting is considered an emergent ability because it only shows significant performance improvements when applied to sufficiently large language models.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</strong> (2023)
    <ul>
      <li>Key idea: A generalization of chain-of-thought prompting. ToT maintains a tree of thoughts, where thoughts represent coherent language sequences that serve as intermediate steps toward solving a problem. Tree-search algorithm like BFS and DFS can be used to traverse the tree.
        <ul>
          <li>ToT is implemented by framing a problem as a search over a tree, where each node is a state representing a partial solution, and each branch is an operator that modifies it. A human user prompts the LLM to solve the problem via a multi-round conversation. Throughout the ToT process, the user plays an active role, monitoring the output, providing feedback, and making strategic decisions.
            <ul>
              <li>Problem definition and decomposition. The human user begins by analyzing the problem and determining how it can be decomposed into a series of smaller, manageable steps.</li>
              <li>Prompt engineering. The human user crafts a set of prompts to guide the LLM through the ToT process. Key prompts include:
                <ul>
                  <li>Propose prompt: instruct LLM to generate next steps.</li>
                  <li>Value prompt: instruct LLM to evaluate generated steps and accessing the likelihoods of leading to a solution.</li>
                  <li>Vote prompt: If the process involves comparing multiple thoughts / partial solutions, instruct the LLM to select the most promising one.</li>
                </ul>
              </li>
              <li>Search algorithm: the user chooses the algorithm to search the tree.</li>
            </ul>
          </li>
          <li>A sample conversation with GPT-4, showcasing ToT prompting.
            <ul>
              <li>Though the paper defines ToT as a multi-round conversations that involves multi-round prompting, GPT-4 can follow the ToT instruction in a single prompt.</li>
              <li>The “Imagine three different experts” prompt is from https://github.com/dave1010/tree-of-thought-prompting</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
User: Imagine three different experts are answering this question.
All experts will write down 1 step of their thinking,
then share it with the group.
Then all experts will go on to the next step, etc.
If any expert realises they're wrong at any point then they leave.

The question is the Game of 24. The numbers are: 7, 1, 4, and 3. You need to use all 4 numbers to reach 24. You can use operators like +, -, *, /. 

Please generate output in ASCII chars only, no markdown.

LLM: Step 1: Expert 1
Let's start by multiplying 7 and 3:
7 * 3 = 21

Step 2: Expert 2
Now, we have 21 and the numbers 1 and 4 left. I'll try adding 4 to 21:
21 + 4 = 25

Step 3: Expert 3
That doesn't give us 24. I think I will try a different approach. I will divide 4 by 1:
4 / 1 = 4

Step 4: Expert 1
We now have 21 and 4. Let me subtract 4 from 21:
21 - 4 = 17

Step 5: Expert 2
Wait, I realize that we need to add something to get 24. I’ll go back to my calculation.
7 * 3 = 21, then I need to subtract 1 from 21:
21 - 1 = 20

Step 6: Expert 3
Hmm, 20 still isn’t the right result. I’m going to leave the discussion.

Step 7: Expert 1
Since Expert 3 left, I’m still trying. Let's add 4 to 20:
20 + 4 = 24!

Final solution:
7 * 3 - 1 + 4 = 24
</code></pre></div></div>

<p><img src="https://github.com/princeton-nlp/tree-of-thought-llm/raw/master/pics/teaser.png" alt="image.png" /></p>]]></content><author><name>Yue Yin</name></author><summary type="html"><![CDATA[The following are notes while reading papers in the 2025 AI Engineer Reading List They are personal notes and are not refined for an external audience really. Just in case it’s helpful for someone else.]]></summary></entry><entry><title type="html">Rust Analyser False Positive</title><link href="https://yyin-dev.github.io/rust/rust-analyser-false-positive/" rel="alternate" type="text/html" title="Rust Analyser False Positive" /><published>2022-12-07T00:00:00-05:00</published><updated>2022-12-07T00:00:00-05:00</updated><id>https://yyin-dev.github.io/rust/rust-analyser-false-positive</id><content type="html" xml:base="https://yyin-dev.github.io/rust/rust-analyser-false-positive/"><![CDATA[<p>When reading TiKV code in VS Code, <code class="language-plaintext highlighter-rouge">cargo build</code> works but rust-analyzer generates false positive error. Error output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ERROR rust_analyzer::lsp_utils] failed to run build scripts

error[E0592]: duplicate definitions with name `generate_files`
  --&gt; /Users/yy0125/.cargo/registry/src/github.com-1ecc6299db9ec823/protobuf-build-0.13.0/src/protobuf_impl.rs:63:5
   |
63 |     pub fn generate_files(&amp;self) {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ duplicate definitions for `generate_files`
   |
  ::: /Users/yy0125/.cargo/registry/src/github.com-1ecc6299db9ec823/protobuf-build-0.13.0/src/prost_impl.rs:5:5
   |
5  |     pub fn generate_files(&amp;self) {
   |     ---------------------------- other definition for `generate_files`


error: aborting due to previous error


For more information about this error, try `rustc --explain E0592`.

error: could not compile `protobuf-build` due to 2 previous errors
</code></pre></div></div>

<p>I noticed that, running the test by clicking <code class="language-plaintext highlighter-rouge">Run</code>, the testcase fails to compile for the same reason. I tried Google but did not find anything helpful.</p>

<p>I also noticed that everything works fine when running the test in JetBrains CLion with Rust extension. So I looked at the commands used by VS Code and CLion to run the test:</p>

<p>VS Code:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cargo run --package raft --example five_mem_node --all-feature
</code></pre></div></div>

<p>CLion:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cargo run --package raft --example five_mem_node 
</code></pre></div></div>

<p>So the problem must be the <code class="language-plaintext highlighter-rouge">--all-feature</code> flag! This must be related to the <code class="language-plaintext highlighter-rouge">defaulte-feature = false</code> in <code class="language-plaintext highlighter-rouge">Cargo.toml</code>, but I am a bit too lazy to dig into this now…</p>

<p>In VS Code <code class="language-plaintext highlighter-rouge">settings.json</code>, comment out <code class="language-plaintext highlighter-rouge">"rust-analyzer.cargo.features": "all",</code>. Everything works now!</p>]]></content><author><name>Yue Yin</name></author><category term="Rust" /><summary type="html"><![CDATA[When reading TiKV code in VS Code, cargo build works but rust-analyzer generates false positive error. Error output:]]></summary></entry><entry><title type="html">My Rust Tour</title><link href="https://yyin-dev.github.io/rust/my-rust-tour/" rel="alternate" type="text/html" title="My Rust Tour" /><published>2022-12-06T00:00:00-05:00</published><updated>2022-12-06T00:00:00-05:00</updated><id>https://yyin-dev.github.io/rust/my-rust-tour</id><content type="html" xml:base="https://yyin-dev.github.io/rust/my-rust-tour/"><![CDATA[<p>Listing my journey of Rust.</p>

<ul>
  <li>2022.9:
    <ul>
      <li>read TRPL again</li>
      <li>Rustlings</li>
    </ul>
  </li>
  <li>2022.10:
    <ul>
      <li><a href="https://github.com/yyin-dev/kv-rs">kv-rs</a>, A log-structured, multi-threaded, persistent key/value storage, with server and client communicating over a custom protocol, implemented in Rust.</li>
      <li>Tried to contribute to risinglight and risingwave. Did not work out well…</li>
    </ul>
  </li>
  <li>2022.11:
    <ul>
      <li><a href="https://github.com/yyin-dev/pngme-rs">pngme-rs</a>, a CLI program to encode secrect message in PNG files.</li>
      <li><a href="https://github.com/yyin-dev/raft-rs">raft-rs</a>, Raft and Percolator in Rust.</li>
    </ul>
  </li>
  <li>2022.12:</li>
</ul>]]></content><author><name>Yue Yin</name></author><category term="Rust" /><summary type="html"><![CDATA[Listing my journey of Rust.]]></summary></entry><entry><title type="html">H Index</title><link href="https://yyin-dev.github.io/leetcode/h-index/" rel="alternate" type="text/html" title="H Index" /><published>2021-09-20T00:00:00-04:00</published><updated>2021-09-20T00:00:00-04:00</updated><id>https://yyin-dev.github.io/leetcode/h-index</id><content type="html" xml:base="https://yyin-dev.github.io/leetcode/h-index/"><![CDATA[<p>Problem:</p>
<ul>
  <li><a href="https://leetcode.com/problems/h-index/">H-Index</a></li>
  <li><a href="https://leetcode.com/problems/h-index-ii/">H-Index II</a></li>
</ul>

<p>The definition</p>

<blockquote>
  <p>A scientist has an index <code class="language-plaintext highlighter-rouge">h</code> if <code class="language-plaintext highlighter-rouge">h</code> of their <code class="language-plaintext highlighter-rouge">n</code> papers have at least <code class="language-plaintext highlighter-rouge">h</code> citations each, and the other <code class="language-plaintext highlighter-rouge">n − h</code> papers have no more than <code class="language-plaintext highlighter-rouge">h</code> citations each.</p>
</blockquote>

<p>implies that <code class="language-plaintext highlighter-rouge">h &gt;= 0</code> and <code class="language-plaintext highlighter-rouge">n-h &gt;= 0</code>, so <code class="language-plaintext highlighter-rouge">0 &lt;= h &lt;= n</code>. Thus, we only need to search in this range.</p>

<p>It’s natural to sort the citations, and verify from 0 to n, if the current value can be a h-index.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
<span class="nl">public:</span>
    <span class="kt">int</span> <span class="n">hIndex</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">C</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// h in [1, n]</span>
        <span class="kt">int</span> <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">sort</span><span class="p">(</span><span class="n">C</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">C</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">;</span> <span class="o">--</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">int</span> <span class="n">h</span> <span class="o">=</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="n">i</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">h</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="o">||</span> <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">h</span><span class="p">))</span> <span class="p">{</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">h</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div>

<p>This graph visualization is amazing.</p>

<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1guni6no1buj60va0u0mye02.jpg" alt="image-20210920111946537" style="zoom:50%;" /></p>

<p>We are trying to find the length of the maximum green square in the historgram. Actually, if the <code class="language-plaintext highlighter-rouge">citations</code> are sorted in ascending order, the graph looks like this:</p>

<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1guni8p8xi4j61180nkdgt02.jpg" alt="image-20210920112144188" style="zoom:50%;" /></p>

<p>H-Index II specifies that <code class="language-plaintext highlighter-rouge">citations</code> are sorted, and requires logrithmic time algorithm, so it strongly hints for binary search.</p>

<p>In the picture above, h = 3, which is the target we are searching for. You should consider the case when you get 1 (you should set <code class="language-plaintext highlighter-rouge">left = mid+1</code>), 3 (you find the target), and 5 (you should update <code class="language-plaintext highlighter-rouge">right = mid-1</code>).</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
<span class="nl">public:</span>
    <span class="kt">int</span> <span class="n">hIndex</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">C</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">left</span> <span class="o">&lt;=</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">int</span> <span class="n">mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">;</span>
            
            <span class="kt">int</span> <span class="n">h</span> <span class="o">=</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="n">mid</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">h</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">mid</span><span class="o">-</span><span class="mi">1</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="o">||</span> <span class="n">C</span><span class="p">[</span><span class="n">mid</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">h</span><span class="p">))</span> <span class="p">{</span>
                <span class="k">return</span> <span class="n">h</span><span class="p">;</span>
            <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">h</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">left</span> <span class="o">=</span> <span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>                
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">right</span> <span class="o">=</span> <span class="n">mid</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div>

<p>Also, there can be at most one h-index: the dashed line crosses the histogram once and at most once.</p>

<h3 id="summary">Summary</h3>

<p>The crucial step is to realize that <code class="language-plaintext highlighter-rouge">0 &lt;= h &lt;= n</code>, and use sorting.</p>

<p>H-Index II provides strong hint. The graph visualization is really helpful for analysis.</p>]]></content><author><name>Yue Yin</name></author><category term="LeetCode" /><summary type="html"><![CDATA[Problem: H-Index H-Index II]]></summary></entry><entry><title type="html">Cpp Compile</title><link href="https://yyin-dev.github.io/tools/Cpp-compile/" rel="alternate" type="text/html" title="Cpp Compile" /><published>2021-06-26T00:00:00-04:00</published><updated>2021-06-26T00:00:00-04:00</updated><id>https://yyin-dev.github.io/tools/Cpp-compile</id><content type="html" xml:base="https://yyin-dev.github.io/tools/Cpp-compile/"><![CDATA[<p>I haven’t write serious C++ code for a while and somehow I have to today. I
totally forgot how to compile C++ code. This is to refresh my memory.</p>

<h2 id="how-c-compilation-works">How C++ compilation works</h2>

<p>See detailed description here: https://github.com/yyin-dev/cpp_primer_solution#c-program-building-process.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Source C++ ---&gt; Expanded C++ ---&gt; Assembly code (.s) ----&gt; Binary (.o) ---&gt; Executable
</code></pre></div></div>

<p>Preprocessing: mainly expand macros (<code class="language-plaintext highlighter-rouge">#include</code>, etc)</p>

<p>Compiling: C++ to object file (<code class="language-plaintext highlighter-rouge">.s</code>)</p>

<p>Assembling: assembly code to binary code (<code class="language-plaintext highlighter-rouge">.o</code>)</p>

<p>Linking: binary code to executable</p>

<p>At compiling, C++ files are compiled separately. Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don’t provide a definition for it. The compiler doesn’t mind this. The definition is not needed until linking.</p>

<p>At linking, linker replaces references to undefined symbols with correct addresses.</p>

<h2 id="related-topics">Related topics</h2>

<p><a href="https://stackoverflow.com/q/333889/9057530">Why C++ source file and header files</a>? The header only provides declaration, and it’s enough for compilation (but not linking).</p>

<p><a href="https://stackoverflow.com/questions/344317/where-does-gcc-look-for-c-and-c-header-files">Where does C++ compiler look for header files</a>? Current directory of the source files, and some predefined directories like <code class="language-plaintext highlighter-rouge">usr/local/include/</code>, etc.</p>

<p>When using a compiler like g++ or clang, you only need to specify the source files (<code class="language-plaintext highlighter-rouge">.cpp</code>). You don’t need to specify header files unless they are not in the current directory and also not in the predefined list of directories.</p>

<p><a href="https://domiyanyue.medium.com/c-development-tutorial-4-static-and-dynamic-libraries-7b537656163e">What’s the difference between static and dynamic library?</a>. Great explanation.</p>]]></content><author><name>Yue Yin</name></author><category term="Tools" /><summary type="html"><![CDATA[I haven’t write serious C++ code for a while and somehow I have to today. I totally forgot how to compile C++ code. This is to refresh my memory.]]></summary></entry><entry><title type="html">Trapwater</title><link href="https://yyin-dev.github.io/leetcode/trapWater/" rel="alternate" type="text/html" title="Trapwater" /><published>2021-05-17T00:00:00-04:00</published><updated>2021-05-17T00:00:00-04:00</updated><id>https://yyin-dev.github.io/leetcode/trapWater</id><content type="html" xml:base="https://yyin-dev.github.io/leetcode/trapWater/"><![CDATA[<h1 id="traping-rain-water">Traping rain water</h1>

<p>Problem: <a href="https://leetcode.com/problems/trapping-rain-water/">Trapping Rain Water</a></p>

<h2 id="solution1-vertical-bar">Solution1: Vertical Bar</h2>

<p>At each slot <code class="language-plaintext highlighter-rouge">i</code>, the amount of water that can be trapped = <code class="language-plaintext highlighter-rouge">min(leftHighestBar, rightHighestBar) - height[i]</code>. This approach is essentially calculting vertical bars (see a, b, c, d ,e in graph).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X           X
X X       X X
X X X   X X X
X X X X X X X

X a b c d e X
X X b c d X X
X X X c X X X
X X X X X X X
</code></pre></div></div>

<p>It’s easy to come up with DP solutions. Time: O(n). Space: O(n)</p>

<h2 id="solution2-horizontal-bar">Solution2: Horizontal Bar</h2>

<p>Can we calculate water horizontally? (See a, b, c in graph)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X           X
X X       X X
X X X   X X X
X X X X X X X

X c c c c c X
X X b b b X X
X X X a X X X
X X X X X X X
</code></pre></div></div>

<p>We can use a monotonic stack for this purpose: for each height, find the closest higher heights to the left and right. See detailed explanation <a href="https://yyin-dev.github.io/leetcode/MonotonicStack/">here</a>.</p>

<h2 id="solution3-two-pointers">Solution3: Two pointers</h2>

<h3 id="variant-1">Variant 1</h3>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
<span class="nl">public:</span>
    <span class="kt">int</span> <span class="n">trap</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">H</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">H</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
        <span class="kt">int</span> <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">leftMax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">rightMax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">left</span> <span class="o">&lt;=</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">leftMax</span> <span class="o">&lt;</span> <span class="n">rightMax</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">leftMax</span> <span class="o">&gt;</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="p">])</span> <span class="p">{</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="n">leftMax</span> <span class="o">-</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">leftMax</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">leftMax</span><span class="p">,</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="o">++</span><span class="p">]);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">rightMax</span> <span class="o">&gt;</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="p">])</span> <span class="p">{</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="n">rightMax</span> <span class="o">-</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">rightMax</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">rightMax</span><span class="p">,</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="o">--</span><span class="p">]);</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div>

<p>Very clear explanation <a href="https://leetcode-cn.com/problems/trapping-rain-water/solution/jie-yu-shui-by-leetcode/327718/">here</a>. The idea is to keep track of <code class="language-plaintext highlighter-rouge">leftMax</code> in <code class="language-plaintext highlighter-rouge">H[:left-1]</code> and <code class="language-plaintext highlighter-rouge">rightMax</code> in <code class="language-plaintext highlighter-rouge">H[right+1:]</code>. For <code class="language-plaintext highlighter-rouge">H[left]</code>, <code class="language-plaintext highlighter-rouge">leftMax</code> correctly tracks the maximum value in <code class="language-plaintext highlighter-rouge">H[:left-1]</code>, whereas <code class="language-plaintext highlighter-rouge">rightMax</code> only tracks max value in <code class="language-plaintext highlighter-rouge">H[right+1:]</code>, leaving <code class="language-plaintext highlighter-rouge">H[left:right]</code> unknown. Can we calculate the water for <code class="language-plaintext highlighter-rouge">H[left]</code> in this case? The asnwer is yes! When <code class="language-plaintext highlighter-rouge">leftMax &lt; rightMax</code>, water trapped at <code class="language-plaintext highlighter-rouge">H[left]</code> will be determined by <code class="language-plaintext highlighter-rouge">leftMax</code>, because maximum value in <code class="language-plaintext highlighter-rouge">H[left:]</code> will be no smaller than <code class="language-plaintext highlighter-rouge">rightMax</code>. Thus, we can calculate the water at <code class="language-plaintext highlighter-rouge">H[left]</code> by <code class="language-plaintext highlighter-rouge">max(0, leftMax - H[left])</code>.</p>

<p>In notation:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>When leftMax &lt; rightMax:
    max{ H[left+1:] } &gt;= max{ H[right+1:] } = rightMax &gt; leftMax = max{ H[:left-1] }
So
    min(max{ H[left+1:] }, max{ H[:left-1] }) = max{ H[:left-1] } = leftMax
</code></pre></div></div>

<p>The idea is simlar: we can calculate water at <code class="language-plaintext highlighter-rouge">H[right]</code> when <code class="language-plaintext highlighter-rouge">leftMax &gt; rightMax</code>.</p>

<h3 id="variant-2">Variant 2</h3>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
<span class="nl">public:</span>
    <span class="kt">int</span> <span class="n">trap</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">H</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">H</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
        <span class="kt">int</span> <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">leftMax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">rightMax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">left</span> <span class="o">&lt;=</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="p">])</span> <span class="p">{</span> <span class="c1">// *</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">leftMax</span> <span class="o">&gt;</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="p">])</span> <span class="p">{</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="n">leftMax</span> <span class="o">-</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">leftMax</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">leftMax</span><span class="p">,</span> <span class="n">H</span><span class="p">[</span><span class="n">left</span><span class="o">++</span><span class="p">]);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">rightMax</span> <span class="o">&gt;</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="p">])</span> <span class="p">{</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="n">rightMax</span> <span class="o">-</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">rightMax</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">rightMax</span><span class="p">,</span> <span class="n">H</span><span class="p">[</span><span class="n">right</span><span class="o">--</span><span class="p">]);</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div>

<p>The only difference from previous approach is <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code>. Why we can do <code class="language-plaintext highlighter-rouge">res += leftMax - H[left]</code> when <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code>? What if <code class="language-plaintext highlighter-rouge">leftMax &lt; rightMax</code>?</p>

<p>The reason is that <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code> implies <code class="language-plaintext highlighter-rouge">leftMax &lt; rightMax</code>. See the following proof.</p>

<p>Proof by contradiction: https://leetcode-cn.com/problems/trapping-rain-water/solution/jie-yu-shui-by-leetcode/868621. Statement: if <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code>, then <code class="language-plaintext highlighter-rouge">H[right]</code> is the maximum value in all <code class="language-plaintext highlighter-rouge">H[:left]</code> and <code class="language-plaintext highlighter-rouge">H[right:]</code>. Proof: (1) suppose the maximum element is not <code class="language-plaintext highlighter-rouge">H[right]</code>, but <code class="language-plaintext highlighter-rouge">H[m]</code> where <code class="language-plaintext highlighter-rouge">m &gt; right</code>. The face that <code class="language-plaintext highlighter-rouge">right</code> decreases from <code class="language-plaintext highlighter-rouge">m</code> to <code class="language-plaintext highlighter-rouge">m-1</code> means that there exists a value in <code class="language-plaintext highlighter-rouge">H[:left]</code> that’s greater than <code class="language-plaintext highlighter-rouge">H[m]</code>, which means <code class="language-plaintext highlighter-rouge">H[m]</code> is not the maximum element. Thus, we reach a contradiction. (2) suppose the maximum element is not <code class="language-plaintext highlighter-rouge">H[right]</code>, but <code class="language-plaintext highlighter-rouge">H[m]</code> where <code class="language-plaintext highlighter-rouge">m &lt; left</code> (clearly <code class="language-plaintext highlighter-rouge">H[left]</code> cannot be the maximum since it’s less than <code class="language-plaintext highlighter-rouge">H[right]</code>). The fact that <code class="language-plaintext highlighter-rouge">left</code> increase from <code class="language-plaintext highlighter-rouge">m</code> to <code class="language-plaintext highlighter-rouge">m+1</code> means that there’s a value in <code class="language-plaintext highlighter-rouge">H[right:]</code> that is greater than <code class="language-plaintext highlighter-rouge">H[m]</code>. Thus, we reach a contradiction. Based on (1) and (2), we know that when <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code>, <code class="language-plaintext highlighter-rouge">H[right]</code> is the maximum value in all travsered values. In other words, <code class="language-plaintext highlighter-rouge">leftMax &lt; rightMax = H[right]</code> holds.</p>

<p>Proof by induction (This proof is inspired by <a href="https://leetcode-cn.com/problems/trapping-rain-water/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-by-w-8/131029">this</a>.). Statement to prove: when <code class="language-plaintext highlighter-rouge">H[left] &lt; H[right]</code>, <code class="language-plaintext highlighter-rouge">H[right]</code> is the maximum of all traversed; when <code class="language-plaintext highlighter-rouge">H[left] &gt; H[right]</code>, <code class="language-plaintext highlighter-rouge">H[left]</code> is the maximum of all traversed. Pre-condition: when <code class="language-plaintext highlighter-rouge">left = 0</code>, <code class="language-plaintext highlighter-rouge">right = n-1</code>, the statement holds. Induction step: suppose the statement holds for <code class="language-plaintext highlighter-rouge">left</code> and <code class="language-plaintext highlighter-rouge">right</code>. You can easily verify that for all four possible situtations, the statements still hold:</p>

<ul>
  <li>H[left] &lt; H[right], and H[left+1] &lt; H[right]</li>
  <li>H[left] &lt; H[right], and H[left+1] &gt; H[right]</li>
  <li>H[left] &gt; H[right], and H[left] &lt; H[right-1]</li>
  <li>H[left] &gt; H[right], and H[left] &lt; H[right-1]</li>
</ul>

<p>The remaining idea is similar to variant1.</p>

<p>In summary, the idea is that the amount of water trapped is determined by the <em>lowest</em> of all boundaries, i.e., when we to calculate the water, we only need to know lowest (not necessarily all). In 2D, there are only two boundaries (left, right).</p>

<p>From the perspective of <code class="language-plaintext highlighter-rouge">H[left]</code> and <code class="language-plaintext highlighter-rouge">H[right]</code>:  <code class="language-plaintext highlighter-rouge">leftMax</code> represents accurate left boundary for <code class="language-plaintext highlighter-rouge">H[left]</code>, inaccurate left boundary for <code class="language-plaintext highlighter-rouge">H[right]</code>; <code class="language-plaintext highlighter-rouge">rightMax</code> represents inaccurate rigth boundary for <code class="language-plaintext highlighter-rouge">H[left]</code>, and accurate right boundary for <code class="language-plaintext highlighter-rouge">H[right]</code>. When <code class="language-plaintext highlighter-rouge">leftMax &lt; rightMax</code>, we are sure that left boundary is the lowest boundary for <code class="language-plaintext highlighter-rouge">H[left]</code>, when <code class="language-plaintext highlighter-rouge">leftMax &gt; rightMax</code>, we are sure that the right boundary is the lowest boundary for <code class="language-plaintext highlighter-rouge">H[right]</code>.</p>

<p>Problem: <a href="https://leetcode.com/problems/trapping-rain-water-ii/">Trapping Rain Water</a>.</p>

<p>This is the 2D variant of the previous problem. Follow the same idea as in 1D: https://leetcode.com/problems/trapping-rain-water-ii/discuss/89495/How-to-get-the-solution-to-2-D-%22Trapping-Rain-Water%22-problem-from-1-D-case. Initially we push all boundaries to the priority queue, and popping from the lowest boundary. Thus, when a slot is popped from the priority_queue, it knows that <em>the lowest of its boundaries</em> is determined, with the value of <code class="language-plaintext highlighter-rouge">currMax</code>. So, the water at this slot can be calculated. Visualization: https://leetcode.com/problems/trapping-rain-water-ii/discuss/89472/Visualization-No-Code</p>]]></content><author><name>Yue Yin</name></author><category term="LeetCode" /><summary type="html"><![CDATA[Traping rain water]]></summary></entry><entry><title type="html">Monotonicstack</title><link href="https://yyin-dev.github.io/leetcode/MonotonicStack/" rel="alternate" type="text/html" title="Monotonicstack" /><published>2021-05-16T00:00:00-04:00</published><updated>2021-05-16T00:00:00-04:00</updated><id>https://yyin-dev.github.io/leetcode/MonotonicStack</id><content type="html" xml:base="https://yyin-dev.github.io/leetcode/MonotonicStack/"><![CDATA[<h2 id="monotonic-stack">Monotonic Stack</h2>

<p>A monotonic stack is just a normal stack, but we can push/pop the stack in certain way so that values in the stack become sorted (ascending/descending).</p>

<p>To build a ascending stack using an array of number:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">monotonicStackExample</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">arr</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">stack</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">stk</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">arr</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">stk</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="n">stk</span><span class="p">.</span><span class="n">top</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
            <span class="n">stk</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
        <span class="p">}</span>
        
        <span class="n">stk</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The above code achieves the following property for the stack:</p>

<ul>
  <li>At the start of iteration, <code class="language-plaintext highlighter-rouge">stk</code> stores values in ascending order;</li>
  <li>At the end of iterating <code class="language-plaintext highlighter-rouge">arr[i]</code>, <code class="language-plaintext highlighter-rouge">stk</code> stores values in ascending order, with <code class="language-plaintext highlighter-rouge">arr[i]</code> on the top of the stack.</li>
</ul>

<p>We can make the following observations, at the iteration for <code class="language-plaintext highlighter-rouge">arr[i]</code>:</p>

<ul>
  <li>Observation #1: When popping element, say <code class="language-plaintext highlighter-rouge">arr[j]</code> (where <code class="language-plaintext highlighter-rouge">j &lt; i</code>) from stack, <code class="language-plaintext highlighter-rouge">arr[i]</code> is the first element smaller than <code class="language-plaintext highlighter-rouge">arr[j]</code>; i.e., <code class="language-plaintext highlighter-rouge">arr[i]</code> is the leftmost element in <code class="language-plaintext highlighter-rouge">arr[j+1:]</code> that’s smaller than <code class="language-plaintext highlighter-rouge">arr[j]</code>;</li>
  <li>Observation #2: After <code class="language-plaintext highlighter-rouge">arr[j]</code> is popped from the stack, the top of the stack, say <code class="language-plaintext highlighter-rouge">arr[k]</code> where <code class="language-plaintext highlighter-rouge">k &lt; j</code>, is the latest element smaller than <code class="language-plaintext highlighter-rouge">arr[j]</code>; i.e., <code class="language-plaintext highlighter-rouge">arr[k]</code> is the rightmost element in <code class="language-plaintext highlighter-rouge">arr[:j-1]</code> that’s smaller than <code class="language-plaintext highlighter-rouge">arr[j]</code>.</li>
</ul>

<p>In this way, we get the closest element around <code class="language-plaintext highlighter-rouge">arr[j]</code> that’s smaller than <code class="language-plaintext highlighter-rouge">arr[j]</code>. Visually, the values look like.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       arr[j]
arr[k]       
              arr[i]
</code></pre></div></div>

<h2 id="properties">Properties</h2>

<p>See if you can understand the following properties. Assume we iterate the array from left to right.</p>

<ul>
  <li>For ascending stack, when an element <code class="language-plaintext highlighter-rouge">arr[i]</code> is popped from the stack, you get
    <ul>
      <li>the rightmost element in <code class="language-plaintext highlighter-rouge">arr[:i-1]</code> that’s smaller than <code class="language-plaintext highlighter-rouge">arr[i]</code>, and</li>
      <li>leftmost element in <code class="language-plaintext highlighter-rouge">arr[i+1:]</code> that’s smaller than <code class="language-plaintext highlighter-rouge">arr[i]</code></li>
    </ul>
  </li>
  <li>For descending stack, when an element <code class="language-plaintext highlighter-rouge">arr[i]</code> is popped from the stack, you get
    <ul>
      <li>the rightmost element in <code class="language-plaintext highlighter-rouge">arr[:i-1]</code> that’s larger than <code class="language-plaintext highlighter-rouge">arr[i]</code>, and</li>
      <li>leftmost element in <code class="language-plaintext highlighter-rouge">arr[i+1:]</code> that’s larger than <code class="language-plaintext highlighter-rouge">arr[i]</code></li>
    </ul>
  </li>
</ul>

<p>Visualization:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ascending stack:
   X
X    X

Descending stack:
X   X
  X
</code></pre></div></div>

<h2 id="apply-to-problems">Apply to problems</h2>

<p>The properties above help you to several categories of algorithm problems:</p>

<p>“Next greater element”: find the closet elment that’s greater than the current element. In <a href="https://leetcode.com/problems/next-greater-element-i/">Leetcode 496</a> and <a href="https://leetcode.com/problems/daily-temperatures/">Leetcode 739. Daily Temperatures</a>, it’s the same as finding the leftmost element that’s greater than current element (<a href="https://github.com/labuladong/fucking-algorithm/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%B3%BB%E5%88%97/%E5%8D%95%E8%B0%83%E6%A0%88.md">reference</a>). So we use a descending stack.</p>

<p>“Closest greater/smaller element”: a generalized case of the “next greater element” problem. In <a href="https://leetcode.com/problems/trapping-rain-water/">Leetcode 42</a>, for each height, find the closest higher heights on both sides; this allows you to calculate water horizontally (<a href="https://leetcode-cn.com/problems/largest-rectangle-in-histogram/solution/84-by-ikaruga/">reference</a>).</p>]]></content><author><name>Yue Yin</name></author><category term="LeetCode" /><summary type="html"><![CDATA[Monotonic Stack]]></summary></entry><entry><title type="html">[5.3] Query Optimization</title><link href="https://yyin-dev.github.io/database/5.3-query-optimization/" rel="alternate" type="text/html" title="[5.3] Query Optimization" /><published>2021-04-23T00:00:00-04:00</published><updated>2021-04-23T00:00:00-04:00</updated><id>https://yyin-dev.github.io/database/%5B5.3%5D-query-optimization</id><content type="html" xml:base="https://yyin-dev.github.io/database/5.3-query-optimization/"><![CDATA[<h2 id="overview">Overview</h2>

<p>Because SQL is declarative, the query only tells the DBMS what to compute, but not how to compute it. The DBMS needs to translate the query into an executable query plan. The job of the DBMS’s optimizer is to pick an optimial plan for a given query.</p>

<p>There are two types of optimization strategies: (1) heuristics: match query to known patterns. This approach may require consulting the system catalog, but never need to examine the data itself; (2) cost estimation: read the data and estimate the cost of executing equivalent plans. Pick the one with the lowest cost.</p>

<h2 id="logical-plan-and-physical-plan">Logical Plan and Physical Plan</h2>

<p>The optimizer generates a mapping from a <em>logical algebra expression</em> to the optimal equivalent <em>physical algebra expression</em>. The logical plan is roughly equivalent to the relational algebra expression in the query. <em>Physical operators</em> define a specific execution strategy using an access path for the different operators in the query plan. There does not always exists a one-to-one mapping from logical to physical plan.</p>

<p>Many query optimization relies on relational algebra equivalence.</p>

<h2 id="cost-estimations">Cost Estimations</h2>

<p>The cost of a query plan depends on CPU, disk I/O, memory, network, etc. Exhaustive enumeration of all possible plans for a query is too expensive. To approximate the cost, DBMS’s maintain internal statistics about tables, attributes, and indexes in the system catalog.</p>

<p>For each relation $ R $, the DBMS maintains:</p>

<ul>
  <li>$ N_R $: the number of tuples in $ R $</li>
  <li>$ V(A, R) $: the number of distinct values of attribute $ A $</li>
</ul>

<p>Techniques include: histogram, sampling.</p>

<h2 id="plan-enumeration">Plan enumeration</h2>

<p>For single-query query plans, the hardest task is to choose the best access methods. Normally heuristics rules are used.</p>

<p>For multi-relation query plans, the number of alternative plans grows rapidly as the number of joins increases. IBM System R only consider left-deep join trees, as they are better suited for the iterator model - the DBMS does not need to materialize the outputs of the join operators.</p>

<p>To make query plans, the DBMS must enumerate the orderings, then the plans for each operator, then the access methods for each table. Dynamci programming can be used.</p>]]></content><author><name>Yue Yin</name></author><category term="Database" /><summary type="html"><![CDATA[Overview]]></summary></entry><entry><title type="html">Terminate Condition</title><link href="https://yyin-dev.github.io/leetcode/terminate-condition/" rel="alternate" type="text/html" title="Terminate Condition" /><published>2021-04-23T00:00:00-04:00</published><updated>2021-04-23T00:00:00-04:00</updated><id>https://yyin-dev.github.io/leetcode/terminate-condition</id><content type="html" xml:base="https://yyin-dev.github.io/leetcode/terminate-condition/"><![CDATA[<p>This post is about the terminate conditions when solving algorithm problems.</p>

<h2 id="binary-search">Binary Search</h2>

<p>The idea of binary search is simple, but there are two variants of implementation.</p>

<h3 id="variant-1">Variant 1</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>while (l &lt; r) {
	int m = l + (r - l) / 2;
	if (...) {
		l = m-1;
	} else {
		r = m;	
	}
}
</code></pre></div></div>

<p>First, you should never use <code class="language-plaintext highlighter-rouge">l = m</code>. When <code class="language-plaintext highlighter-rouge">l + 1 &gt;= m</code>, this causes infinite loop. Thus, we use <code class="language-plaintext highlighter-rouge">l = m-1</code> and <code class="language-plaintext highlighter-rouge">r = m</code>. However, even with <code class="language-plaintext highlighter-rouge">r = m</code>, you should avoid having <code class="language-plaintext highlighter-rouge">l == r</code>, which cause infinite lsoop again. Conclusion: when using <code class="language-plaintext highlighter-rouge">r=m</code>, use <code class="language-plaintext highlighter-rouge">l &lt; r</code> to avoid infinite loop.</p>

<h3 id="variant-2">Variant 2</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>while (l &lt;= r) {
	int m = l + (r - l) / 2;
	if (...) {
		l = m-1;
	} else {
		r = m+1;	
	}
}
</code></pre></div></div>

<p>For <code class="language-plaintext highlighter-rouge">l = m-1</code> and <code class="language-plaintext highlighter-rouge">r = m+1</code>, no infinite loop is possible, so you can use <code class="language-plaintext highlighter-rouge">l &lt;= r</code>.</p>

<h2 id="two-pointers">Two pointers</h2>

<p>Should you use <code class="language-plaintext highlighter-rouge">l &lt; r</code> or <code class="language-plaintext highlighter-rouge">l &lt;= r</code>? Answer: if you want <code class="language-plaintext highlighter-rouge">while</code> to execute for <code class="language-plaintext highlighter-rouge">l == r</code>, use <code class="language-plaintext highlighter-rouge">l &lt;= r</code>. Otherwise, use <code class="language-plaintext highlighter-rouge">l &lt; r</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>while (l &lt; r) {
   // ...
}
</code></pre></div></div>]]></content><author><name>Yue Yin</name></author><category term="LeetCode" /><summary type="html"><![CDATA[This post is about the terminate conditions when solving algorithm problems.]]></summary></entry><entry><title type="html">[5.4] Concurrency Control</title><link href="https://yyin-dev.github.io/database/5.4-concurrency-control/" rel="alternate" type="text/html" title="[5.4] Concurrency Control" /><published>2021-04-23T00:00:00-04:00</published><updated>2021-04-23T00:00:00-04:00</updated><id>https://yyin-dev.github.io/database/%5B5.4%5D-concurrency-control</id><content type="html" xml:base="https://yyin-dev.github.io/database/5.4-concurrency-control/"><![CDATA[<h2 id="transactions">Transactions</h2>

<p>Goal: correctness + efficiency.</p>

<p>ACID:</p>

<ul>
  <li>atomicity: either all actions in the transaction happen, or none happen</li>
  <li>consistency: if the transaction is consistent and the database is consistent at the beginning of the transaction, then the database is guaranteed to be consistent when the transaction completes.</li>
  <li>isolation: when a transaction executes, it should have the illusion that it is isolated from other transactions.</li>
  <li>durability: if a transaction commits, its effect on the database should persist.</li>
</ul>

<h3 id="atomicity">Atomicity</h3>

<p>There are two approaches: Logging, and Shadow Paging.</p>

<p>In logging, the DBMS logs all actions so that it can undo the actions of aborted transactions. Most widely used.</p>

<p>In shadow paging, the DBMS makes copies of pages modified by the transactions and transactions make changes to those copies.Only when the transaction commits is the page made available. Compared with logging, this is slower at runtime but faster at recovery.</p>

<h3 id="consistency">Consistency</h3>

<p>Logical correctness of the database.</p>

<h3 id="isolation">Isolation</h3>

<p>The DBMS provides the illusion that they are running alone in the system, and do not see the effects of concurrent transactions. This is <strong>equivalent</strong> to a system where transaction execute in <strong>serial order</strong> but with better performance. The DBMS must interleave the operations of concurrent transactions while maintaining the illusion of isolation.</p>

<p>A <em>concurrency control protocol</em> is how the DBMS decides the proper interleaving of operations in concurrent transactions at runtime. There are two categories of concurrency control protocols: <strong>pessimistic</strong> and <strong>optimistic</strong>.</p>

<p>The order in which the DBMS executes operations is called <em>execution schedule</em>. The goal of concurrency control protocol is to generate an execution schedule equivalent to some serial execution:</p>

<ul>
  <li>Serial schedule: no interleaving happens.</li>
  <li>Equivalent schedule: two schedules are equivalent if the effect of executing the first schedule is identical to the effect of executing the second schedule, for any database state.</li>
  <li>Serializable schedule: a serializable schedule is a schedule equivalent to any serial schedule.</li>
</ul>

<p>A <em>conflict</em> between two operations occur if the operations are from different transactions, being performed on the same object, and at least one of them is a write. There are three types of conflicts:</p>

<ul>
  <li>Read-write conflicts (unrepeatable read): a transaction see different values when reading an object multiplt times.</li>
  <li>Write-read conflicts (dirty read): a transaction sees the write effects of an uncommitted transaction</li>
  <li>Write-write conflict (lost update): a transaction overwrites the uncommited writes by another concurrent transaction.</li>
</ul>

<p>DBMS typically supports <em>conflict serializability</em>. Two schedules are <em>conflict equivalent</em> is they involve the same operations of the same transactions, and every pair of conflicting operations is ordered in the same way in both schedules. A schedule is <em>conflict serializable</em> if it is conflict equivalent to some serial schedule.</p>

<p>One can verify that a schedule is conflict serializable by swapping non-conflict operations until a serial schedule is formed. For schdules with many transactions, this can be expensive. A better way is to use a <em>dependency graph</em>.</p>

<p>In a dependency graph, each transaction is a node. A directed edge from node T1 to node T2 exists if and only if an operation O1 in N1 conflicts with an operation O2 in N2, and O1 occurs before O2 in the schedule. The schedule is conflict serializable if the dependency graph is acyclic.</p>

<h3 id="durability">Durability</h3>

<p>All changes of committed transactions must be durable, even after a crash or restart. Method: logging, shadow paging.</p>

<h2 id="two-phase-locking-2pl">Two-Phase Locking (2PL)</h2>

<p>A dependency graph tells you if a existing schedule is serializable, but cannot generate the schdule for you at runtime. A DBMS can use locks to dynamically generate serializable schedule for transactions at runtime. A centralized transaction manager maintains a lock table to decide whether a transaction can acquire a lock or not. The lock table doesn’t need to be durable as any active transaction when the DBMS crashes is automatically aborted.</p>

<p>Two-phase locking (2PL) is a pessimistic concurrency control protocol. In the growing phase, a transaction acquires locks. The transaction enters the shrinking phase immediately after it releases the first lock. The transaction cannot acquire locks any more in the shrinking phase.</p>

<p>A schedule is <em>strict</em> if any value written by a transaction is not read/overwritten by another transaction until the first transaction commits. <em>Strict 2PL</em> only releases locks on commit. The advantage strict 2PL is that it doesn’t incur cascading aborts. The disadvantage is that it limits concurrency even more.</p>

<h3 id="deadlock-handling">Deadlock Handling</h3>

<p>There are two appraches to handle deadlocks: detection and prevention.</p>

<p>In <em>deadlock detection</em>, the DBMS creates a waits-for graph where transactions are nodes and there exists a directed edge from Ti to Tj if transaction Ti is waiting for transaction Tj to release a lock. The DBMS can launch a background thread to periodically check for cycles in the waits-for graph and break the cycles by selecting “victim” transaction(s) to abort. The victim transaction will either restart or abort depending on the application. Multiple transaction properties can be considered when selecting a victim.</p>

<p>Instead of letting transactons to acquire any lock they need and deal with deadlocks afterwards, <em>deadlock prevention</em> 2PL stops transactions from causing deadlocks before they occur. When a transaction tries to acquire a lock held by another transaction (which could cause a deadlock), the DBMS kills one of them. To implement this, transactions are assigned priorities based on timestamps (older transactions have higher priority). The schems guarantee no deadlocks as only one direction is allowed when waiting for a lock. When a transaction restarts, it uses the <strong><em>original</em></strong> timestamp, to avoid starvation.</p>

<h3 id="lock-granularity">Lock granularity</h3>

<p>Tuple-level lock is very expensive. Hierarchical locking reduces the overhead. For example, a lock on the table is much cheaper than locking all tuples in the table. <strong>Intention locks</strong> allow a higher level node to be locked in shared/exclusive mode without checking all decendant nodes.</p>

<h2 id="timestamp-ordering">Timestamp Ordering</h2>

<p>Timestamp ordering (T/O) is a class of optimistic concurrency control protocols. Two properties:</p>

<ul>
  <li>Each transacton Ti is assigned a <em>unique</em>, <em>fixed</em> timestamp that’s monotonically increasing.</li>
  <li>If TS(Ti) &lt; TS(Tj), the execution schedule is equivalent to a serial schedule where Ti appears before Tj.</li>
</ul>

<p>To allocate timestamps, you can use system clock, but with edge cases like daylight savings. You can also use logical counter, but must deal with overflows. Some systems use hybrid approach. Also, maintaining the timestamp across a distributed system is hard.</p>

<h3 id="basic-to">Basic T/O</h3>

<p>No locks are used. Every database object X is tagged with a timestamp of the last transaction that successfully perform a read (R-TS(X)) or write (W-TS(X)). The DBMS checks the timestamp for every operation. If a transaction tries to access an object in a way that violates the timestamp ordering, the transaction is aborted and restarted.</p>

<p>For read, the ordering is violated if TS(Ti) &lt; W-TS(X), so Ti is restarted with the same timestamp. Otherwise, the read is performed and R-TS(X) is updated to be max{R-TS(X), TS(Ti)}. It makes a local copy of X to ensure repeatable read.</p>

<p>For write, if TS(Ti) &lt; R-TS(X) or TS(Ti) &lt; W-TS(X), Ti must be restarted with a new timestamp. Otherwise, the write is performed and W-TS(X) is updated to be TS(Ti). It makes a local copy of X to ensure repeatable read.</p>

<p>Possible problems: (1) high overhead from making copies for repeatable read; (2) long running transactions can get starved; (3) suffers from timestamp allocation bottleneck on highly concurrent system.</p>

<h3 id="optimistic-concurrency-control-occ">Optimistic Concurrency Control (OCC)</h3>

<p>Optimistic concurrency control (OCC) is another optimistic concurrency control protocol that uses timestamps. In OCC, a <em>private workspace</em> is created for each DBMS. Any object read is copied into the workspace, and any object written is copied into the workspace and modified there. No other transactions can read the changes made by a transaction in its private workspace.</p>

<p>When a transaction commits, the DBMS compares the transaction’s workspace <em>write set</em> to see whether it conflicts with other transactions. If there’s no conflicts, the write set is installed into the “global” database. OCC consists of 3 phases:</p>

<ul>
  <li>Work phase: the DBMS tracks read/write sets of transactions and store writes in a private workspace;</li>
  <li>Validation phase: before a transaction commits, the DBMS checks if it conflicts with other transactions.</li>
  <li>Write phase: if validation succeeds, apply the private workspace changes to the database. Otherwise, restart txn.</li>
</ul>

<p>The DBMS assigns transaction timestamps when they enter the validation phase. Transaction that havn’t entered the validation phase are assigned a timestamp of infinity. To ensure serializable schedule, the DBMS checks Ti against other transactions for RW or WW conflicts and makes sure that all conflict are in one direction (e.g older -&gt; younger). There’re two methods for this phase: backward validation, and forward validation. Backward validation checks if the read/write set of commiting transaction intersects with those of the committed ones. Forward validation checks if the read/write set of commiting transaction intersects with those not yet committed.</p>

<p>If TS(Ti) &lt; TS(Tj), then one of the following three conditions must hold to pass the validation phase:</p>

<ul>
  <li>Ti completes all three phases before Tj begins;</li>
  <li>Ti completes before Tj starts its write phase, and Ti does not write to any object read by Tj (Suppose Ti doesn’t abort and its write set intersects with Tj, Tj’s write could depend on the stale value, and later overwrites the value written by Ti. This is incorrect - a transaction with larger timestamp should not miss the writes by another transaction with lower timestamp);</li>
  <li>Ti completes Work phase before Tj completes its Work phase, and Ti doesn’t write to any object read/written by Tj.</li>
</ul>

<p>Possible problems: (1) high overhead for copying data locally into private workspace; (2) validation/write phase bottleneck (latching needed to avoid data race); (3) aborts are wasteful; (4) timestamp allocation bottleneck.</p>

<h2 id="ioslation-levels">Ioslation Levels</h2>

<table>
  <thead>
    <tr>
      <th>Isolation levels</th>
      <th>Behavior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>read uncommitted</td>
      <td>all anomalies</td>
    </tr>
    <tr>
      <td>read committed</td>
      <td>no dirty read</td>
    </tr>
    <tr>
      <td>repeatable read (snapshot isolation)</td>
      <td>no dirty read, no unrepeatable read</td>
    </tr>
    <tr>
      <td>serializable</td>
      <td>no dirty read, no unrepeatable read, no phantom</td>
    </tr>
  </tbody>
</table>

<p>How to avoid phantom read? What’s the difference from nonrepeatable read?: https://stackoverflow.com/a/23138849</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                    Implementation
Serializable         strict 2PL; index lock;
Repeatable read      strict 2PL (S-locks released on commit/abort)
Read committed       strict 2PL; acquiring/releasing S-locks doesn't affect growing/shrinking phase, and S-locks are
                     immediately released after each read (and re-acquired later if needs to read).
Read uncommitted     strict 2PL; not acquiring S-locks for read
</code></pre></div></div>

<h2 id="multi-version-concurrency-control">Multi-Version Concurrency Control</h2>

<p><strong>MVCC is the most widely used scheme in DBMS</strong>, it’s more than a concurrency control protocol. It’s mainly about determining the visibility of writes to transactions.</p>

<p>With MVCC, the DBMS mtaintains multiple <strong>physical</strong> version of a single <strong>logical</strong> object. When a transaction writes to an object, the DBMS creates a new version of that object. When a transaction reads an object, it reads the newest version that existed when the transaction started. It won’t see any writes that are not committed yet when the transaction starts. For detailed explanation of MVCC execution and the usage of transaction status table, refer to Lecture 19 slides.</p>

<p>The fundamental concept/benefit of MVCC is that writes do not block writers, and readers do not block writers. This means one transaction can modify an object while other transactions read old versions. Also, read-only transactions can read a consistent snapshot of the database without using any locks.</p>

<p>There are four important MVCC design decisions:</p>

<ul>
  <li>Concurrency Control Protocol</li>
  <li>Version Storage</li>
  <li>Garbage Collection</li>
  <li>Index Management</li>
</ul>

<h3 id="concurrency-control-protocol">Concurrency Control Protocol</h3>

<p>For concurrency control protocl, you can choose among 2PL, T/O and OCC.</p>

<h3 id="version-storage">Version Storage</h3>

<p>Version storage is about how the DBMS stores different physical versions of a logical object and how transactions find the newest version visible to them. The DBMS uses the tuple’s pointer field to create a <em>version chain</em> per logical tuple, which is a linked list of versions sorted by timestamp. Indexes alwasy point to the “head” of the chain, which is either the newest or oldest version depending on implementation. A thread traverses the chain until it finds the correct version.</p>

<p>Different storage schemes determine where/what to store for each version:</p>

<ul>
  <li>
    <p><strong>Append-only storage</strong>. All physical versions of a logical tuple are stored in the same table space. Versions are mixed together in the table and each update appends a new version of the tuple into the table, and updates the version chain.</p>

    <p><img src="/home/yy0125/.config/Typora/typora-user-images/image-20210423132114894.png" alt="image-20210423132114894" /></p>
  </li>
  <li>
    <p><strong>Time-travel storage</strong>. The DBMS maintains a sperate table called the time-travel table to store older versions of the tuple. On every update, the DBMS copies the old version of the tuple to the time-travel table, and overwrites the tuple in the main table with the new data. Pointers of the tuple in the main table point to old versions in the time-travel table.</p>

    <p><img src="/home/yy0125/.config/Typora/typora-user-images/image-20210423132342010.png" alt="image-20210423132342010" /></p>
  </li>
  <li>
    <p><strong>Delta storage</strong>. Delta storage uses a separate table similar to time-travel storage, but only stores the deltas (changes between tuples). Transactions can recreate older versions by iterating through the deltas. This has faster write than time-travel storage, but slower reads.</p>
  </li>
</ul>

<h3 id="garbage-collection">Garbage collection</h3>

<p>The DBMS remove <em>reclaimable</em> physical versions from the database over time. A version is reclaimable if no active transaction can see that version, or if it was created by an aborted transaction.</p>

<p>For <em>tuple-level GC</em>, the DBMS finds old versions by scanning tuples directly. This can be done by a background thread periodically, A simple optimization is to maintain a “dirty page bitmap”, which keeps track of the pages that have been modified since previous scan. This help the thread to skip pages that havn’t changed. Another approach is for worker threads to identify reclaimable versions as they traverse the version chain.</p>

<p>For <em>transaction-level GC</em>, each transaction is responsible for tracking their own old versions so that DBMS doesn’t have to scan tuples. Each transaction maintains its own read/write set. When it commits/aborts, the DBMS can use that to identify which tuples to reclaim.</p>

<h3 id="index-management">Index Management</h3>

<p>All primary key indexes always point to the version chain head.</p>]]></content><author><name>Yue Yin</name></author><category term="Database" /><summary type="html"><![CDATA[Transactions]]></summary></entry></feed>