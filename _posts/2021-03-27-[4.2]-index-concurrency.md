---
layout: single
categories: 
    - Database
author: Yue Yin

toc: true
toc_sticky: true
---

## TLDR

```
+--------------------+
| Query Planning     |
+--------------------+
| Operator Execution |
+--------------------+
|   Access Methods   | <-
+--------------------+
|Buffer Pool Manager |
+--------------------+
|   Disk Manager     |
+--------------------+
```

Latch vs Lock.

How to implement a latch?

Index concurrency control: hash table; B+ tree. 

## Index Concurrency Control

A *concurrency control protocol* is the way a DBMS ensures concurrent operations produce "correct" results. The definition of correctness can vary:
- Logical correctness: the visibility of data to some thread.
- Physical correctness: the invariant of data structures. 
For index concurrency control, we care about the physical correctness of the index data structure.

## Locks vs. Latches

|                      | Locks                        | Latches                   |
| -------------------- | ---------------------------- | ------------------------- |
| What's separated?    | User transactions            | Threads                   |
| What's protected?    | Database's logical contents  | In-memory data structures |
| How long is it held? | Throughout the transaction   | Critical sections         |
| Modes                | Shared, Exclusive, Intention | Read, Write               |
| Deadlock             | Detection/Avoidance          | Avoidance                 |
| ... by ...           | Waits-for, Timeout, Aborts   | Coding discipline         |
| Managed by           | Lock manager                 | Internal data structures  |
| Rollback support?    | Yes                          | No                        |


### Rollback support

Why locks need to support rollback, while latches don't? 

Consider the execution of a transaction. When updating tables, the corresponding indexes are also updated. To update an index, the DBMS acquires the latch, writes to the index data structure, and releases the latch. To rollback a transaction:
```
rollback_txn(txn) {
    rollback_tables(txn.table_write_set);
    rollback_indexes(txn.index_write_set);
    release_locks(txn);
}

rollback_indexes(index_write_set) {
    for idx in index_write_set {
        rollback_index(idx)
    }
}
```

The internal implementation of `rollback_index` will acquire the latch, rollback any previous changes, and release the latch. The difference between lock and latch here is that, the rollback is performed while holding the lock, while the initial writes to the index and following rollbacks to the index are done in two separate `acquire-write-release` steps. This is not considered as rollback on the latch. 

### Latch implementation

There are different ways to implement a latch for a DBMS:

- Blocking OS mutex
    
    This is internally implemented using [futex](https://yyin-dev.github.io/os/futex/). The OS will put the thread to sleep if it cannot acquire the latch.

- Spin latches

    Spin latches are more efficient than OS mutex as it avoids the user-kernel context switch. The simplest spin latch simply spins in a loop until it acquires latch, which wastes CPU cycles. However, as the DBMS knows its own workloads, it can tune the spin latch to either retry, yield, or abort. The reason is similar to why the DBMS implements its own buffer pool manager: the DBMS knows its own stuff, and does a better job.

- Read/Write Latch

    Based on the underlying primitives (either OS mutex or spin latch), the DBMS can build read-write latch. Read latch is also denoted as S(shared) latch, and write latch is also denoted as X(exclusive) latch.

## Hash Table Latching

In general, there are two approaches to latch a hash table:
- Page latch: each page has its own read-write latch. This decreases parallelism because potentially only one thread can access a page at a time, but accessing multiple slots within a page is fast.
- Slot latch: each slot has its own latch. This increases parallilism but increases the overhead. 

Deadlock is impossible because all threads acquire/release latches in the same direction. 

## B+ Tree Latching

*Latch crabbing* protocol allows threads to concurrently access/modify a B+ tree. The idea is as follows: acquire latch for parent; acquire latch for child; if the child is safe, release the latch for parent. A node is safe if it will not split or merge (not full on insertion or less than half full on deletion). 

### Basic Latch Crabbing Protocol

- Search: start at root and go down, repeatedly acquire latch on child and than unlatch parent.
- Insert/Delete: start at root and go down, obtaining X latches. Once child is latched, check if it's safe. If so, release latches on all ancestors. 

Note: when you coalesce/redistribute for deletion, you must wlatch the sibling as well. 

### Improvied Latch Crabbing Protocol

In basic protocol, every insert/delete transaction must wlatch on the root page, which limits parallelism. Instead, each transaction can assume that split/merge is rare, and only use rlatch crabbing, and verify each node when going down the tree. If any node is unsafe, then perform the basic protocol (i.e. acquire wlatches). 

- Search: same as basic protocol.
- Insert/Delete: take rlatches as if for search. Arrive at leaf and take wlatch. If leaf is not safe, release all previous latches and restart transaction using basic protocol. 

### Leaf Node Scan

If threads only perform search/insert/delete, latches are acquired and released in the same direction. Thus, no deadlock will occur. 

Leaf node scans are susceptible to deadlocks (assume leaf nodes are doubly-linked), as locks can be acquired in different directions (left-to-right and right-to-left). Index latches don't support deadlock detection or avoidance, so we can only rely on coding discipline. The leaf node sibling latching acquisition must support "no-wait" mode: if a thread cannot acquire a latch, it must abort and retry. 